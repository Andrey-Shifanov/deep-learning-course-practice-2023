{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f50051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\soup4\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4a332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Downloading tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.12.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Downloading numpy-1.26.3-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\soup4\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.42.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.2-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Collecting ml-dtypes~=0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.1.1)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.33.0)\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.4-cp39-cp39-win_amd64.whl (422 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.60.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.7.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.26.2-py2.py3-none-any.whl (186 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.9)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, google-auth, tensorboard-data-server, protobuf, numpy, grpcio, google-auth-oauthlib, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, ml-dtypes, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.0.2\n",
      "    Uninstalling keras-3.0.2:\n",
      "      Successfully uninstalled keras-3.0.2\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.26.2 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.0 keras-2.15.0 libclang-16.0.6 ml-dtypes-0.2.0 numpy-1.26.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 requests-oauthlib-1.3.1 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\soup4\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\soup4\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\soup4\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\soup4\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.26.3 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.3 which is incompatible.\n",
      "google-cloud-storage 1.31.0 requires google-auth<2.0dev,>=1.11.0, but you have google-auth 2.26.2 which is incompatible.\n",
      "google-cloud-core 1.7.1 requires google-auth<2.0dev,>=1.24.0, but you have google-auth 2.26.2 which is incompatible.\n",
      "google-api-core 1.25.1 requires google-auth<2.0dev,>=1.21.1, but you have google-auth 2.26.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836502be",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 28\n",
    "h = 28\n",
    "res = w * h\n",
    "rate = 0.1\n",
    "hidden_layer = 300\n",
    "classes = 10\n",
    "epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbcb0a",
   "metadata": {},
   "source": [
    "Загрузка набора данных MNIST и нормализация значений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d38f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "train_X = train_X.reshape(-1, w * h).astype('float32') / 255\n",
    "test_X = test_X.reshape(-1, w * h).astype('float32') / 255\n",
    "train_y = to_categorical(train_y, classes)\n",
    "test_y = to_categorical(test_y, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357dd3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 784)\n",
      "Y_train: (60000, 10)\n",
      "X_test:  (10000, 784)\n",
      "Y_test:  (10000, 10)\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.32941177 0.7254902\n",
      " 0.62352943 0.5921569  0.23529412 0.14117648 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.87058824 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.94509804 0.7764706  0.7764706  0.7764706  0.7764706\n",
      " 0.7764706  0.7764706  0.7764706  0.7764706  0.6666667  0.20392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2627451  0.44705883 0.28235295 0.44705883 0.6392157  0.8901961\n",
      " 0.99607843 0.88235295 0.99607843 0.99607843 0.99607843 0.98039216\n",
      " 0.8980392  0.99607843 0.99607843 0.54901963 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06666667 0.25882354 0.05490196\n",
      " 0.2627451  0.2627451  0.2627451  0.23137255 0.08235294 0.9254902\n",
      " 0.99607843 0.41568628 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3254902  0.99215686 0.81960785 0.07058824\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.08627451\n",
      " 0.9137255  1.         0.3254902  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.5058824  0.99607843 0.93333334\n",
      " 0.17254902 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.23137255 0.9764706  0.99607843 0.24313726 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.52156866 0.99607843\n",
      " 0.73333335 0.01960784 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.03529412 0.8039216  0.972549   0.22745098 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.49411765\n",
      " 0.99607843 0.7137255  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.29411766 0.9843137  0.9411765  0.22352941\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.07450981\n",
      " 0.8666667  0.99607843 0.6509804  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.79607844 0.99607843 0.85882354\n",
      " 0.13725491 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.14901961 0.99607843 0.99607843 0.3019608  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.12156863 0.8784314  0.99607843\n",
      " 0.4509804  0.00392157 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.52156866 0.99607843 0.99607843 0.20392157 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.23921569 0.9490196\n",
      " 0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.4745098  0.99607843 0.99607843 0.85882354\n",
      " 0.15686275 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4745098  0.99607843 0.8117647  0.07058824 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))\n",
    "print(test_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee485334",
   "metadata": {},
   "source": [
    "Отображение даных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e125cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "num_images = 9\n",
    "\n",
    "grid_size = int(np.sqrt(num_images))\n",
    "fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(train_X[i].reshape(w, h), cmap='gray')\n",
    "    )\n",
    "    ax.set_title(f\"Label: {np.argmax(train_y[i])}\")\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee346c",
   "metadata": {},
   "source": [
    "Создание модели нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4272d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, time: 6.558, accuracy: 0.938, loss : 0.207\n",
      "Epoch 1, time: 6.610, accuracy: 0.961, loss : 0.131\n",
      "Epoch 2, time: 6.592, accuracy: 0.971, loss : 0.096\n",
      "Epoch 3, time: 6.441, accuracy: 0.978, loss : 0.075\n",
      "Epoch 4, time: 7.423, accuracy: 0.982, loss : 0.061\n",
      "Epoch 5, time: 6.866, accuracy: 0.985, loss : 0.051\n",
      "Epoch 6, time: 6.924, accuracy: 0.988, loss : 0.044\n",
      "Epoch 7, time: 6.922, accuracy: 0.989, loss : 0.037\n",
      "Epoch 8, time: 6.558, accuracy: 0.991, loss : 0.033\n",
      "Epoch 9, time: 6.976, accuracy: 0.992, loss : 0.029\n",
      "Epoch 10, time: 7.448, accuracy: 0.993, loss : 0.025\n",
      "Epoch 11, time: 6.750, accuracy: 0.994, loss : 0.023\n",
      "Epoch 12, time: 6.548, accuracy: 0.995, loss : 0.020\n",
      "Epoch 13, time: 6.531, accuracy: 0.996, loss : 0.018\n",
      "Epoch 14, time: 6.651, accuracy: 0.996, loss : 0.016\n",
      "Epoch 15, time: 6.590, accuracy: 0.996, loss : 0.015\n",
      "Epoch 16, time: 7.227, accuracy: 0.997, loss : 0.014\n",
      "Epoch 17, time: 6.824, accuracy: 0.997, loss : 0.013\n",
      "Epoch 18, time: 7.110, accuracy: 0.998, loss : 0.011\n",
      "Epoch 19, time: 7.275, accuracy: 0.998, loss : 0.010\n"
     ]
    }
   ],
   "source": [
    "def ReLU(x):\n",
    "    \"\"\"Rectified Linear Unit activation function.\"\"\"\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def softMax(x):\n",
    "    \"\"\"Softmax activation function.\"\"\"\n",
    "    ex = np.exp(x - np.max(x, axis=1, keepdims=True))  # Prevent overflow\n",
    "    return ex / np.sum(ex, axis=1, keepdims=True)\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, input_layer: int, hidden_layer: int, output_layer: int, learning_rate: float):\n",
    "        \"\"\"Initialize the neural network model.\"\"\"\n",
    "        self.input_layer = input_layer\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.output_layer = output_layer\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "       \n",
    "        self.input_weights = np.random.randn(input_layer, hidden_layer) * 0.01\n",
    "        self.hidden_bias = np.zeros((1, hidden_layer))\n",
    "        \n",
    "        self.hidden_weights = np.random.randn(hidden_layer, output_layer) * 0.01\n",
    "        self.output_bias = np.zeros((1, output_layer))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward propagation.\"\"\"\n",
    "        self.values_first = x.dot(self.input_weights) + self.hidden_bias\n",
    "        self.values_first_ReLU = ReLU(self.values_first)\n",
    "        self.values_second = self.values_first_ReLU.dot(self.hidden_weights) + self.output_bias\n",
    "        self.values_second_softmax = softMax(self.values_second)\n",
    "        return self.values_second_softmax\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        \"\"\"Perform backpropagation.\"\"\"\n",
    "        answer = np.eye(self.output_layer)[y]\n",
    "        \n",
    "        dlt2 = (self.values_second_softmax - answer) / self.values_second_softmax.shape[0]\n",
    "        dReLU = np.where(self.values_first > 0, 1, 0)\n",
    "        dlt1 = dlt2.dot(self.hidden_weights.T) * dReLU\n",
    "        dW2 = self.values_first_ReLU.T.dot(dlt2)\n",
    "        dW1 = x.T.dot(dlt1)\n",
    "        \n",
    "        self.hidden_weights -= self.learning_rate * dW2\n",
    "        self.input_weights -= self.learning_rate * dW1\n",
    "        self.hidden_bias -= self.learning_rate * np.sum(dlt1, axis=0, keepdims=True)\n",
    "        self.output_bias -= self.learning_rate * np.sum(dlt2, axis=0, keepdims=True)\n",
    "    \n",
    "    def cross_entropy_loss(self, u, y):\n",
    "        \"\"\"Calculate the cross-entropy loss.\"\"\"\n",
    "        logits_for_answers = u[np.arange(len(u)), y]\n",
    "        loss = -np.log(logits_for_answers)\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def accuracy(self, predictions, labels):\n",
    "        \"\"\"Calculate the accuracy of the predictions.\"\"\"\n",
    "        return np.mean(np.argmax(predictions, axis=1) == labels)\n",
    "\n",
    "Net = Model(res, hidden_layer, classes, rate)\n",
    "times = []\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    for batch in range(0, len(train_X), batch_size):\n",
    "        images = train_X[batch:batch + batch_size]\n",
    "        labels = np.argmax(train_y[batch:batch + batch_size], axis=1)  # Преобразуем one-hot в индексы\n",
    "        Net.forward(images)\n",
    "        Net.backward(images, labels)\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "    result = Net.forward(train_X)\n",
    "    # Используем индексы меток для вычисления точности и потерь\n",
    "    labels_idx = np.argmax(train_y, axis=1)\n",
    "    print(\"Epoch {}, time: {:.3f}, accuracy: {:.3f}, loss : {:.3f}\"\n",
    "          .format(epoch, times[-1], Net.accuracy(result, labels_idx), Net.cross_entropy_loss(result, labels_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980a5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
